{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1beb26",
   "metadata": {},
   "source": [
    "# Chua Ki Min Clement 7083543\n",
    "## CSCI 316 Indivual Assignment 1 Task 2\n",
    "### Dataset: Census Income\n",
    "##### Source: https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "### Objective: The objective of this task is to implement from scratch Decision Tree classification method to predict whether the incomes exceed 50K/yr based on census data. Thus, this is a binary classification problem. The training and test sets are pre-defined in the data set (i.e., in “adult.data” and “adult.test”).\n",
    "### Requirement:\n",
    "##### (1) Implement two DT models by choosing any two (2) split criteria from Information Gain, Gain Ratio, Gini Index and Variance. Note that you can use either binary-split or multiple-split. \n",
    "##### (2) Use (approximately) 2/3 records in “adult.data” for training, and 1/3 records in “adult.data” for post\u0002pruning. \n",
    "##### (3) Report the accuracy of each model.\n",
    "##### (4) All DT models must be self-implemented. You CANNOT use any machine learning library in this task. \n",
    "##### (5) It is recommended that your implementation includes a “tree induction function”, a “classification function” and a “post-pruning function”.\n",
    "##### (6) You can (but not must) use any suitable pre-processing method. You also can (but not must) use any reasonable early stopping criteria (pre-pruned parameters such as number of splits, minimum data set size, and split threshold) to improve the training speed. If you do so, explain your reasons. \n",
    "##### (7) Present clear and accurate explanation of your implementation and results (in the Markdown format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faddee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing librarys needed for this task \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421aeda",
   "metadata": {},
   "source": [
    "###  Import adult.data file which i converted to a csv file as a dataframe and split it into 2/3 records for training and 1/3 for validation for post-pruning. Afterwards i will reset the index so that the index starts from 0 to prevent any errors later on such as testing between the testing dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883f5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing our dataset adult file\n",
    "columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\n",
    "           \"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"]\n",
    "df=pd.read_csv('adult.data',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f61bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate df dataframe, split it into training and validation for post-pruning\n",
    "dfdupl=df.copy()\n",
    "dftrain=dfdupl.sample(frac=0.67,random_state=1)\n",
    "dfpostp=dfdupl.drop(dftrain.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfde7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relabel the index starting from 0\n",
    "dftrain=dftrain.reset_index(drop=True)\n",
    "dfpostp=dfpostp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb965d6",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "### Even though that there is no nan values in our dataset however there is special characters such as '?' in some columns. So i replaced it with nan values and drop the indexes that contain any nan values in it.\n",
    "### Some features/columns has many distinct unique values however some columns has too many unique values such as 'fnlwgt', 'age' , 'capital-gain', 'capital-loss', 'native-country' and may cause inefficiencies when building our decision tree model hence i drop it.  'education' and 'education-num' is similar  so i drop education-num .\n",
    "### Changing all categorical features/columns into numerical data using the map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29efab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1243\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1247\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     396\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the '?' in dataframe \n",
    "dftrain.isin(['?']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f48754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace '?' to nan and then drop the columns\n",
    "dftrain[dftrain=='?']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c02b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1243\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1247\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     396\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking whether it is replace to null\n",
    "dftrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4a95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values\n",
    "dftrain.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8ffafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :\n",
      "31    593\n",
      "33    562\n",
      "34    562\n",
      "25    561\n",
      "36    561\n",
      "     ... \n",
      "77      6\n",
      "85      3\n",
      "83      2\n",
      "84      2\n",
      "88      1\n",
      "Name: age, Length: 71, dtype: int64\n",
      "workclass :\n",
      "Private             14925\n",
      "Self-emp-not-inc     1652\n",
      "Local-gov            1387\n",
      "State-gov             862\n",
      "Self-emp-inc          708\n",
      "Federal-gov           648\n",
      "Without-pay             9\n",
      "Name: workclass, dtype: int64\n",
      "fnlwgt :\n",
      "113364    10\n",
      "203488     9\n",
      "148995     9\n",
      "164190     9\n",
      "111483     9\n",
      "          ..\n",
      "233428     1\n",
      "182237     1\n",
      "97030      1\n",
      "73091      1\n",
      "93169      1\n",
      "Name: fnlwgt, Length: 15111, dtype: int64\n",
      "education :\n",
      "HS-grad         6589\n",
      "Some-college    4453\n",
      "Bachelors       3374\n",
      "Masters         1078\n",
      "Assoc-voc        852\n",
      "11th             720\n",
      "Assoc-acdm       676\n",
      "10th             556\n",
      "7th-8th          379\n",
      "Prof-school      357\n",
      "9th              306\n",
      "Doctorate        263\n",
      "12th             260\n",
      "5th-6th          197\n",
      "1st-4th          103\n",
      "Preschool         28\n",
      "Name: education, dtype: int64\n",
      "education-num :\n",
      "9     6589\n",
      "10    4453\n",
      "13    3374\n",
      "14    1078\n",
      "11     852\n",
      "7      720\n",
      "12     676\n",
      "6      556\n",
      "4      379\n",
      "15     357\n",
      "5      306\n",
      "16     263\n",
      "8      260\n",
      "3      197\n",
      "2      103\n",
      "1       28\n",
      "Name: education-num, dtype: int64\n",
      "marital-status :\n",
      "Married-civ-spouse       9360\n",
      "Never-married            6532\n",
      "Divorced                 2871\n",
      "Separated                 613\n",
      "Widowed                   542\n",
      "Married-spouse-absent     256\n",
      "Married-AF-spouse          17\n",
      "Name: marital-status, dtype: int64\n",
      "occupation :\n",
      "Prof-specialty       2707\n",
      "Exec-managerial      2681\n",
      "Craft-repair         2676\n",
      "Adm-clerical         2509\n",
      "Sales                2406\n",
      "Other-service        2193\n",
      "Machine-op-inspct    1279\n",
      "Transport-moving     1038\n",
      "Handlers-cleaners     911\n",
      "Farming-fishing       659\n",
      "Tech-support          609\n",
      "Protective-serv       423\n",
      "Priv-house-serv        93\n",
      "Armed-Forces            7\n",
      "Name: occupation, dtype: int64\n",
      "relationship :\n",
      "Husband           8313\n",
      "Not-in-family     5162\n",
      "Own-child         2997\n",
      "Unmarried         2205\n",
      "Wife               915\n",
      "Other-relative     599\n",
      "Name: relationship, dtype: int64\n",
      "race :\n",
      "White                 17350\n",
      "Black                  1890\n",
      "Asian-Pac-Islander      596\n",
      "Amer-Indian-Eskimo      202\n",
      "Other                   153\n",
      "Name: race, dtype: int64\n",
      "sex :\n",
      "Male      13609\n",
      "Female     6582\n",
      "Name: sex, dtype: int64\n",
      "capital-gain :\n",
      "0        18503\n",
      "15024      217\n",
      "7688       176\n",
      "7298       152\n",
      "99999      100\n",
      "         ...  \n",
      "5060         1\n",
      "1173         1\n",
      "22040        1\n",
      "4931         1\n",
      "18481        1\n",
      "Name: capital-gain, Length: 112, dtype: int64\n",
      "capital-loss :\n",
      "0       19224\n",
      "1902      122\n",
      "1887      107\n",
      "1977      106\n",
      "1848       37\n",
      "        ...  \n",
      "2472        1\n",
      "1755        1\n",
      "2282        1\n",
      "155         1\n",
      "2201        1\n",
      "Name: capital-loss, Length: 83, dtype: int64\n",
      "hours-per-week :\n",
      "40    9473\n",
      "50    1835\n",
      "45    1186\n",
      "60     922\n",
      "35     815\n",
      "      ... \n",
      "94       1\n",
      "92       1\n",
      "86       1\n",
      "82       1\n",
      "95       1\n",
      "Name: hours-per-week, Length: 89, dtype: int64\n",
      "native-country :\n",
      "United-States                 18397\n",
      "Mexico                          431\n",
      "Philippines                     119\n",
      "Germany                          86\n",
      "Puerto-Rico                      78\n",
      "Canada                           74\n",
      "El-Salvador                      68\n",
      "India                            68\n",
      "Cuba                             67\n",
      "England                          52\n",
      "South                            50\n",
      "China                            49\n",
      "Jamaica                          47\n",
      "Italy                            44\n",
      "Vietnam                          44\n",
      "Dominican-Republic               41\n",
      "Columbia                         39\n",
      "Japan                            39\n",
      "Guatemala                        37\n",
      "Poland                           35\n",
      "Taiwan                           28\n",
      "Iran                             26\n",
      "Haiti                            25\n",
      "Portugal                         25\n",
      "Nicaragua                        20\n",
      "France                           19\n",
      "Ecuador                          19\n",
      "Ireland                          19\n",
      "Peru                             18\n",
      "Greece                           18\n",
      "Hong                             14\n",
      "Laos                             13\n",
      "Cambodia                         13\n",
      "Yugoslavia                       12\n",
      "Honduras                         11\n",
      "Thailand                         11\n",
      "Trinadad&Tobago                  10\n",
      "Outlying-US(Guam-USVI-etc)        9\n",
      "Scotland                          8\n",
      "Hungary                           7\n",
      "Holand-Netherlands                1\n",
      "Name: native-country, dtype: int64\n",
      "income :\n",
      "<=50K    15271\n",
      ">50K      4920\n",
      "Name: income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#finding value counts for each feature/column\n",
    "for c in dftrain[columns]:\n",
    "    print (\"%s :\" % c)\n",
    "    print(dftrain[c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b27f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :\n",
      "71\n",
      "workclass :\n",
      "7\n",
      "fnlwgt :\n",
      "15111\n",
      "education :\n",
      "16\n",
      "education-num :\n",
      "16\n",
      "marital-status :\n",
      "7\n",
      "occupation :\n",
      "14\n",
      "relationship :\n",
      "6\n",
      "race :\n",
      "5\n",
      "sex :\n",
      "2\n",
      "capital-gain :\n",
      "112\n",
      "capital-loss :\n",
      "83\n",
      "hours-per-week :\n",
      "89\n",
      "native-country :\n",
      "41\n",
      "income :\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#finding the number of unique values in each feature/column\n",
    "for i in dftrain:\n",
    "    print (\"%s :\" % i)\n",
    "    print (dftrain[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3093b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping this features/columns based on the uniquness of data \n",
    "dftrain.drop(['age', 'fnlwgt', 'capital-gain','capital-loss', 'native-country','education-num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f50d43",
   "metadata": {},
   "source": [
    "## Finding all unique values in each feature/column\n",
    "### 'workclass' : 'Self-emp-inc': 0, 'State-gov': 1,'Federal-gov': 2, 'Without-pay': 3, 'Local-gov': 4,'Private': 5, 'Self-emp-not-inc': 6\n",
    "### 'education' : 'Some-college': 0, 'Preschool': 1, '5th-6th': 2, 'HS-grad': 3, 'Masters': 4, '12th': 5, '7th-8th': 6, 'Prof-school': 7,'1st-4th': 8, 'Assoc-acdm': 9, 'Doctorate': 10, '11th': 11,'Bachelors': 12, '10th': 13,'Assoc-voc': 14,'9th': 15\n",
    "### 'marital-status: 'Married-spouse-absent': 0,'Married-civ-spouse': 1, 'Married-AF-spouse': 2, 'Widowed': 3, 'Separated': 4, 'Divorced': 5,'Never-married': 6\n",
    "### 'occupation' : 'Farming-fishing': 0, 'Tech-support': 1, 'Adm-clerical': 2, 'Handlers-cleaners': 3, 'Prof-specialty': 4,'Machine-op-inspct': 5, 'Exec-managerial': 6,'Priv-house-serv': 7,'Craft-repair': 8,'Sales': 9, 'Transport-moving': 10, 'Armed-Forces': 11, 'Other-service': 12,'Protective-serv':13\n",
    "### 'relationship': 'Not-in-family': 0, 'Wife': 1, 'Other-relative': 2, 'Unmarried': 3,'Husband': 4,'Own-child': 5\n",
    "### 'race' feature/column: 'Black': 0, 'Asian-Pac-Islander': 1,'Other': 2,'Amer-Indian-Eskimo': 3, 'White': 4\n",
    "### 'sex' feature/column: 'Male': 0, 'Female': 1\n",
    "### 'income' : '<=50K': 0, '>50K': 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad36b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass :\n",
      "['Self-emp-not-inc' 'Private' 'Local-gov' 'Federal-gov' 'State-gov'\n",
      " 'Self-emp-inc' 'Without-pay']\n",
      "education :\n",
      "['7th-8th' '11th' 'Bachelors' 'HS-grad' 'Some-college' 'Masters'\n",
      " 'Assoc-voc' '5th-6th' '10th' '12th' 'Doctorate' 'Assoc-acdm'\n",
      " 'Prof-school' '9th' '1st-4th' 'Preschool']\n",
      "marital-status :\n",
      "['Widowed' 'Never-married' 'Married-civ-spouse' 'Divorced' 'Separated'\n",
      " 'Married-spouse-absent' 'Married-AF-spouse']\n",
      "occupation :\n",
      "['Other-service' 'Farming-fishing' 'Prof-specialty' 'Machine-op-inspct'\n",
      " 'Handlers-cleaners' 'Exec-managerial' 'Adm-clerical' 'Craft-repair'\n",
      " 'Sales' 'Transport-moving' 'Tech-support' 'Priv-house-serv'\n",
      " 'Protective-serv' 'Armed-Forces']\n",
      "relationship :\n",
      "['Not-in-family' 'Other-relative' 'Own-child' 'Husband' 'Unmarried' 'Wife']\n",
      "race :\n",
      "['White' 'Black' 'Asian-Pac-Islander' 'Other' 'Amer-Indian-Eskimo']\n",
      "sex :\n",
      "['Female' 'Male']\n",
      "hours-per-week :\n",
      "[66 25 50 40 64 45 30 60 36 35 48 20 42 80 65 43 58 37 70 44 28 16 15 39\n",
      " 51 75 10 55 90 24 38 62 13  9 52 14 61 54  8  7 32  3  6 26 47 99 84 56\n",
      " 18 21 23 72  5 53 33 57 22 12 46 49 68 76 31 63 41  4 19 17  2 27 96 78\n",
      " 34 11 85 95 97 98  1 67 81 82 59 29 92 91 86 94 77]\n",
      "income :\n",
      "['<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "dftrain_column = columns = [\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\n",
    "                            \"hours-per-week\",\"income\"]\n",
    "for c in dftrain[dftrain_column]:\n",
    "    print (\"%s :\" % c)\n",
    "    print(dftrain[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07214a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categoricals data in the dataset to numericals data \n",
    "dftrain['workclass']= dftrain['workclass'].map({'Self-emp-inc': 0, 'State-gov': 1,'Federal-gov': 2, 'Without-pay': 3, \n",
    "                                                'Local-gov': 4,'Private': 5, 'Self-emp-not-inc': 6}).astype(int)\n",
    "dftrain['education']= dftrain['education'].map({'Some-college': 0, 'Preschool': 1, '5th-6th': 2, 'HS-grad': 3, \n",
    "                                                'Masters': 4, '12th': 5, '7th-8th': 6, 'Prof-school': 7,'1st-4th': 8, \n",
    "                                                'Assoc-acdm': 9, 'Doctorate': 10, '11th': 11,'Bachelors': 12, \n",
    "                                                '10th': 13,'Assoc-voc': 14,'9th': 15}).astype(int)\n",
    "dftrain['marital-status'] = dftrain['marital-status'].map({'Married-spouse-absent': 0,'Married-civ-spouse': 1, \n",
    "                                                           'Married-AF-spouse': 2, 'Widowed': 3, 'Separated': 4, \n",
    "                                                           'Divorced': 5,'Never-married': 6}).astype(int)\n",
    "dftrain['occupation'] = dftrain['occupation'].map({ 'Farming-fishing': 0, 'Tech-support': 1, 'Adm-clerical': 2, \n",
    "                                                   'Handlers-cleaners': 3, 'Prof-specialty': 4,'Machine-op-inspct': 5, \n",
    "                                                   'Exec-managerial': 6,'Priv-house-serv': 7,'Craft-repair': 8,'Sales': 9, \n",
    "                                                   'Transport-moving': 10, 'Armed-Forces': 11, 'Other-service': 12,\n",
    "                                                   'Protective-serv':13}).astype(int)\n",
    "dftrain['relationship'] = dftrain['relationship'].map({'Not-in-family': 0, 'Wife': 1, 'Other-relative': 2, 'Unmarried': 3,\n",
    "                                                       'Husband': 4,'Own-child': 5}).astype(int)\n",
    "dftrain['race'] = dftrain['race'].map({'Black': 0, 'Asian-Pac-Islander': 1,'Other': 2,'Amer-Indian-Eskimo': 3, \n",
    "                                       'White': 4}).astype(int)\n",
    "dftrain['sex'] = dftrain['sex'].map({'Male': 0, 'Female': 1}).astype(int)\n",
    "dftrain['income']=dftrain['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b68c6",
   "metadata": {},
   "source": [
    "## First decision tree model that i am implementing is using information gain alogrithm \n",
    "### We first have to calculate the entropy of our dataset of our target feature which is 'income' and for all features.\n",
    "### Afterwards we will then compute information gain for all features to find out which is the best features which has the highest information gain to be the splitting node and build our decision tree model based on these informations.\n",
    "### For our decision tree model we define the stopping criteria, if one of this is satisfied, we return to a leaf node. If the dataset is empty, return the mode target feature value in the original dataset. If the feature space is empty, return the mode target feature value of the direct parent node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db169f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the entropy of a dataset, argument of this function is the col parameter which specifies the target column\n",
    "def entropy(col):\n",
    "    elements,counts = np.unique(col,return_counts = True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff87396",
   "metadata": {},
   "source": [
    "### Calculate the information gain of a dataset. This function has three argument where the first is the dataset of the feature the informationgain should be calculated.Second is the feature the information gain should be calculated, third is the name of the target feature which is 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06774e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate entropy,weighted entropy,values and counts for the split attribute and information gain\n",
    "def InfoGain(data,split_attribute_name,target_name=\"income\"):\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).\n",
    "                                                                  dropna()[target_name]) for i in range(len(vals))])\n",
    "    information_Gain = total_entropy - Weighted_Entropy\n",
    "    return information_Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22532a",
   "metadata": {},
   "source": [
    "##  This builds the tree, and this function has 5 arguments the first and second is the dataset that is use to build the tree the second argument is in the case the dataset delivered by the first parameter is empty. Third is the features of the dataset, fourth is the target attribute and the last argument is the class of the mode target feature value of the parent node for a specific node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "443601b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_tree_model(data,originaldata,features,target_attribute_name=\"income\",parent_node_class = None):\n",
    "\n",
    "    \n",
    "    \n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],\n",
    "                                                                                  return_counts=True)[1])]\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],\n",
    "                                                                                       return_counts=True)[1])]\n",
    "        \n",
    "        #Select the feature which best splits the dataset\n",
    "        #Return the information gain values for the features in the dataset\n",
    "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] \n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #The root gets the name of the feature (best_feature) with the maximum informatio gain in the first run\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Remove the feature with the best inforamtion gain from the feature space\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Split the dataset along the value of the feature with the largest information gain\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            \n",
    "            #Call the information gain algorithm for each of those sub_datasets with the new parameters\n",
    "            subtree = information_gain_tree_model(sub_data,df,features,target_attribute_name,parent_node_class)\n",
    "            \n",
    "\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b3f9f",
   "metadata": {},
   "source": [
    "### Prediction function takes two argument which first is the instance of a new unknown data which shape is a dictionary and the second is the tree that has been build. Check the new query which contains a dictionary for features in our tree and check if the name of the root node is equal to one of the query features. If true, run down the root node outgoing branch whose value equals to the value of query feature equals to root node. If at the end of the the branch a leaf node which is not a dict object we return the value which is the prediction. However if there is another node we search in the query for the feature which equals the value of that node. We look up the value of our query feature and run down the branch whose value is equl to the query feature value. However a default will be reutrn if that is an error or no classification is possible for the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fcdb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prediction of new data \n",
    "def predict(query,tree,default = 1):\n",
    "\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return default\n",
    "\n",
    "            result = tree[key][query[key]]\n",
    "\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "\n",
    "            else:\n",
    "                return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fc90b",
   "metadata": {},
   "source": [
    "### Check the accuracy of our tree\n",
    "### Create a new query instances by removing the target feature column from the original dataset and convert it into a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b2e6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(data,tree):\n",
    "\n",
    "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
    "    \n",
    "\n",
    "    predicted = pd.DataFrame(columns=[\"predicted\"]) \n",
    "\n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0) \n",
    "    print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data[\"income\"])/len(data))*100,'%')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fbd5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tree of our training set using the model of the information gain algorithm\n",
    "tree = information_gain_tree_model(dftrain,dftrain,dftrain.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8666a0",
   "metadata": {},
   "source": [
    "###  Import adult.test file as a dataframe. I will reset the index so that the index starts from 0 to prevent any errors later on such as testing between the testing dataset.  Also clean all the special characters in the dataframe as there is also '?' in the testing dataset and same as our training set i will remove all irrelevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d7898b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing test adult dataset \n",
    "columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\n",
    "           \"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"]\n",
    "df2=pd.read_csv('adult.test',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba43c2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "workclass         963\n",
       "fnlwgt              0\n",
       "education           0\n",
       "education-num       0\n",
       "marital-status      0\n",
       "occupation        966\n",
       "relationship        0\n",
       "race                0\n",
       "sex                 0\n",
       "capital-gain        0\n",
       "capital-loss        0\n",
       "hours-per-week      0\n",
       "native-country    274\n",
       "income              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the '?' in dataframe \n",
    "df2.isin(['?']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ca7dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace '?' to nan and then drop the columns\n",
    "df2[df2=='?']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bccf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values\n",
    "df2.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "426476e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relabel the index starting from 0\n",
    "df2=df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6cf616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping this features/columns same as our training data \n",
    "df2.drop(['age', 'fnlwgt', 'capital-gain','capital-loss', 'native-country','education-num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3941fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all categorical data in the dataset to numerical data\n",
    "df2['workclass']= df2['workclass'].map({'Self-emp-inc': 0, 'State-gov': 1,'Federal-gov': 2, 'Without-pay': 3, \n",
    "                                        'Local-gov': 4,'Private': 5, 'Self-emp-not-inc': 6}).astype(int)\n",
    "df2['education']= df2['education'].map({'Some-college': 0, 'Preschool': 1, '5th-6th': 2, 'HS-grad': 3, 'Masters': 4, \n",
    "                                        '12th': 5, '7th-8th': 6, 'Prof-school': 7,'1st-4th': 8, 'Assoc-acdm': 9, \n",
    "                                        'Doctorate': 10, '11th': 11,'Bachelors': 12, '10th': 13,\n",
    "                                        'Assoc-voc': 14,'9th': 15}).astype(int)\n",
    "df2['marital-status'] = df2['marital-status'].map({'Married-spouse-absent': 0,'Married-civ-spouse': 1, \n",
    "                                                   'Married-AF-spouse': 2, 'Widowed': 3, 'Separated': 4, \n",
    "                                                   'Divorced': 5,'Never-married': 6}).astype(int)\n",
    "df2['occupation'] = df2['occupation'].map({ 'Farming-fishing': 0, 'Tech-support': 1, 'Adm-clerical': 2, \n",
    "                                           'Handlers-cleaners': 3, 'Prof-specialty': 4,'Machine-op-inspct': 5, \n",
    "                                           'Exec-managerial': 6,'Priv-house-serv': 7,'Craft-repair': 8,'Sales': 9, \n",
    "                                           'Transport-moving': 10, 'Armed-Forces': 11, 'Other-service': 12,\n",
    "                                           'Protective-serv':13}).astype(int)\n",
    "df2['relationship'] = df2['relationship'].map({'Not-in-family': 0, 'Wife': 1, 'Other-relative': 2, 'Unmarried': 3,\n",
    "                                               'Husband': 4,'Own-child': 5}).astype(int)\n",
    "df2['race'] = df2['race'].map({'Black': 0, 'Asian-Pac-Islander': 1,'Other': 2,'Amer-Indian-Eskimo': 3, \n",
    "                               'White': 4}).astype(int)\n",
    "df2['sex'] = df2['sex'].map({'Male': 0, 'Female': 1}).astype(int)\n",
    "df2['income']=df2['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78f2e512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  75.77689243027889 %\n"
     ]
    }
   ],
   "source": [
    "# testing the accuracy of our testing set with our tree that is build with the training set\n",
    "accuracy_test(df2,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0ece9",
   "metadata": {},
   "source": [
    "## Second decision tree model that i am implementing is using variance alogrithm \n",
    "### Calculate the homogeneity of a node, if a node is entirely homogeneous, then the variance is zero.\n",
    "### For each split, indivdually calculate each child node variance and calculate the variance of each split as the weighted average variance of child nodes\n",
    "### Select the split with the lowest variance and then perform it recursively until completely homogeneous nodes are achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4837c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the feature values\n",
    "def unique(seq, return_counts=False, id=None):\n",
    "   \n",
    "    found = set()\n",
    "    if id is None:\n",
    "        for x in seq:\n",
    "            found.add(x)\n",
    "           \n",
    "    else:\n",
    "        for x in seq:\n",
    "            x = id(x)\n",
    "            if x not in found:\n",
    "                found.add(x)\n",
    "    found = list(found)           \n",
    "    counts = [seq.count(0),seq.count(1)]\n",
    "    if return_counts:\n",
    "        return found,counts\n",
    "    else:\n",
    "        return found\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a50e51e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total values in each features\n",
    "def sum(data):\n",
    "    sum = 0\n",
    "    for i in data:\n",
    "        sum = sum + i\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfb3b2",
   "metadata": {},
   "source": [
    "### Calculate the variance of the dataset feature/column. This function has one argument where the first is the feature the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c077b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance(target_values):\n",
    "    values = list(target_values)\n",
    "    elements,counts = unique(values,True)\n",
    "    variance_impurity = 0\n",
    "    sum_counts = sum(counts)\n",
    "    for i in elements:\n",
    "        variance_impurity += (-counts[i]/sum_counts*(counts[i]/sum_counts))\n",
    "    return variance_impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9771e",
   "metadata": {},
   "source": [
    "### To decide the optimal split for our algorithm from a noot rode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fded1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_impurity_gain(data, split_attribute_name, target_attribute_name):\n",
    "    data_split = data.groupby(split_attribute_name)\n",
    "    aggregated_data = data_split.agg({target_attribute_name : [calculate_variance, lambda x: len(x)/(len(data.index) * 1.0)] \n",
    "                                     })[target_attribute_name]\n",
    "    aggregated_data.columns = ['Variance', 'Observations']\n",
    "    weighted_variance_impurity = sum( aggregated_data['Variance'] * aggregated_data['Observations'] )\n",
    "    total_variance_impurity = calculate_variance(data[target_attribute_name])\n",
    "    variance_impurity_gain = total_variance_impurity - weighted_variance_impurity\n",
    "    return variance_impurity_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82a75e",
   "metadata": {},
   "source": [
    "##  This builds the tree, and this function has 4 arguments the first is the dataset that is use to build the tree the second argument is the target attribute of the dataset, third is the feature/columnand the last argument is just an argument is when the dataset is empty will return none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6b8c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_using_variance_impurity(data, target_attribute_name, attribute_names, default_class=None):\n",
    "    global node_number_variance\n",
    "    from collections import Counter\n",
    "    count_set = Counter(x for x in data[target_attribute_name])\n",
    "    if len(count_set) == 1:\n",
    "        return list(count_set.keys())[0]\n",
    "\n",
    "    elif data.empty or (not attribute_names):\n",
    "        return default_class \n",
    "    \n",
    "    else:\n",
    "        index_of_max = list(count_set.values()).index(max(count_set.values())) \n",
    "        default_class = list(count_set.keys())[index_of_max]\n",
    "        variance_gain = [variance_impurity_gain(data, attr, target_attribute_name) for attr in attribute_names]\n",
    "        index_of_max = variance_gain.index(max(variance_gain)) \n",
    "        best_attr = attribute_names[index_of_max]\n",
    "         \n",
    "        #The root gets the name of the feature (best_feature)\n",
    "        tree = {best_attr:{}}\n",
    "        positiveCount = data['income'].value_counts()[1];\n",
    "        negativeCount = data['income'].value_counts()[0];\n",
    "        if positiveCount>negativeCount :\n",
    "            best_class = 1\n",
    "        elif positiveCount<negativeCount:\n",
    "            best_class = 0\n",
    "        else:\n",
    "            best_class = 'none'\n",
    "        tree[best_attr]['best_class'] = best_class\n",
    "        node_number_variance = node_number_variance + 1\n",
    "\n",
    "        remaining_attribute_names = [i for i in attribute_names if i != best_attr]\n",
    "\n",
    "        for attr_val, data_subset in data.groupby(best_attr):\n",
    "            subtree = build_tree_using_variance_impurity(data_subset,\n",
    "                        target_attribute_name,\n",
    "                        remaining_attribute_names,\n",
    "                        default_class)\n",
    "            tree[best_attr][attr_val] = subtree\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec3cb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_number_variance = 0\n",
    "labelValues = list(dftrain.columns.values)\n",
    "labelValues.remove('income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbd7623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building our second tree with the features and attributes\n",
    "tree2 = build_tree_using_variance_impurity(dftrain,'income',labelValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3730b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  75.28552456839309 %\n"
     ]
    }
   ],
   "source": [
    "# testing the accuracy of tree2\n",
    "accuracy_test(df2,tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90543d8",
   "metadata": {},
   "source": [
    "### For our validation dataset that is use for post pruning, i would also do the same thing as previous dataset to change all special characters '?' to null values and drop it. I would also drop the same inefficent feature/column same as our previous training dataset however i would drop a extra hours-per-week as i feel that it is not needed as there are too many different values. \n",
    "### I will build my tree using the validation data and test the accuracy to see if there is any difference in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3ef99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace '?' to nan and then drop the columns\n",
    "dfpostp[dfpostp=='?']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dee7cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values\n",
    "dfpostp.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c3f7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all categorical data in the dataset to numerical data for our validation set\n",
    "dfpostp.drop(['age', 'fnlwgt', 'capital-gain','capital-loss', 'native-country','education-num','hours-per-week'],\n",
    "             axis=1, inplace=True)\n",
    "dfpostp['workclass']= dfpostp['workclass'].map({'Self-emp-inc': 0, 'State-gov': 1,'Federal-gov': 2, 'Without-pay': 3, \n",
    "                                                'Local-gov': 4,'Private': 5, 'Self-emp-not-inc': 6}).astype(int)\n",
    "dfpostp['education']= dfpostp['education'].map({'Some-college': 0, 'Preschool': 1, '5th-6th': 2, 'HS-grad': 3, \n",
    "                                                'Masters': 4, '12th': 5, '7th-8th': 6, 'Prof-school': 7,'1st-4th': 8, \n",
    "                                                'Assoc-acdm': 9, 'Doctorate': 10, '11th': 11,'Bachelors': 12, '10th': \n",
    "                                                13,'Assoc-voc': 14,'9th': 15}).astype(int)\n",
    "dfpostp['marital-status'] = dfpostp['marital-status'].map({'Married-spouse-absent': 0,'Married-civ-spouse': 1, \n",
    "                                                           'Married-AF-spouse': 2, 'Widowed': 3, 'Separated': 4, \n",
    "                                                           'Divorced': 5,'Never-married': 6}).astype(int)\n",
    "dfpostp['occupation'] = dfpostp['occupation'].map({ 'Farming-fishing': 0, 'Tech-support': 1, 'Adm-clerical': 2, \n",
    "                                                   'Handlers-cleaners': 3, 'Prof-specialty': 4,'Machine-op-inspct': 5,\n",
    "                                                   'Exec-managerial': 6,'Priv-house-serv': 7,'Craft-repair': 8,'Sales': \n",
    "                                                   9, 'Transport-moving': 10, 'Armed-Forces': 11, 'Other-service': 12,\n",
    "                                                   'Protective-serv':13}).astype(int)\n",
    "dfpostp['relationship'] = dfpostp['relationship'].map({'Not-in-family': 0, 'Wife': 1, 'Other-relative': 2, 'Unmarried': 3,\n",
    "                                                       'Husband': 4,'Own-child': 5}).astype(int)\n",
    "dfpostp['race'] = dfpostp['race'].map({'Black': 0, 'Asian-Pac-Islander': 1,'Other': 2,'Amer-Indian-Eskimo': 3, \n",
    "                                       'White': 4}).astype(int)\n",
    "dfpostp['sex'] = dfpostp['sex'].map({'Male': 0, 'Female': 1}).astype(int)\n",
    "dfpostp['income']=dfpostp['income'].map({'<=50K': 0, '>50K': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7457d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will also drop my testing dataset hours-per-week so that i can test with my validation dataset\n",
    "df2.drop(['hours-per-week'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd252b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune for infogain model tree\n",
    "tree3 = information_gain_tree_model(dfpostp,dfpostp,dfpostp.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b70a0d",
   "metadata": {},
   "source": [
    "### Looking at the accuracy for our tree3(information gain algorithm) 78.811% and tree 4(variance alogorithm) 78.685% after removing unnecessary column for post pruning comparing to our tree(information gain algorithm) 75.637 % and tree2(variance algorithm) 75.133% we can see the difference after doing post pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32ca0e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  78.77158034528553 %\n"
     ]
    }
   ],
   "source": [
    "# testing the accuracy of our tree\n",
    "accuracy_test(df2,tree3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b4a1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelValues = list(dfpostp.columns.values)\n",
    "labelValues.remove('income')\n",
    "tree4 = build_tree_using_variance_impurity(dfpostp,'income',labelValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4443844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  78.59229747675963 %\n"
     ]
    }
   ],
   "source": [
    "# testing the accuracy of our tree\n",
    "accuracy_test(df2,tree4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a996995",
   "metadata": {},
   "source": [
    "## Predicting with one of our tree using our predict function by creating a query using a dictionary containing key and values of our features and some of the values that can be found in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5a45ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'workclass':5,'education':11,'marital-status':5,'occupation':5,'relationship':5,'race':0,'sex':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c3246bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = pd.Series(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e501f675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(query,tree4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
